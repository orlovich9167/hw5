## Обзор ANN-алгоритмов

### IVF_FLAT (Inverted File Index with Flat search)

**Принцип:** Пространство векторов разбивается на кластеры (Voronoi cells) с помощью k-means. При поиске сначала определяются ближайшие кластеры, затем внутри них выполняется полный перебор.

**Параметры:**
- `nlist` (128) — количество кластеров. Больше кластеров → быстрее поиск, но ниже recall при малом nprobe
- `nprobe` (16) — сколько кластеров просматривать при поиске. Больше → выше recall, но медленнее

**Trade-off:** Точный поиск внутри кластеров (без потери точности от квантизации), но ограниченный набор кандидатов. При достаточном nprobe даёт recall, близкий к 1.0. Потребление памяти — полные векторы хранятся без сжатия.

### HNSW (Hierarchical Navigable Small World)

**Принцип:** Строится многослойный граф, где верхние слои содержат крупные «шаги» между узлами, а нижние — мелкие. Поиск начинается с верхнего слоя и спускается вниз, каждый раз уточняя результат.

**Параметры:**
- `M` (16) — максимальное число соседей на каждом уровне графа. Больше M → лучше recall, но больше памяти
- `efConstruction` (200) — размер динамического списка кандидатов при построении. Больше → качественнее граф, но дольше построение
- `ef` (64) — размер списка кандидатов при поиске. Больше → выше recall, медленнее поиск

**Trade-off:** Не требует кластеризации, хорошо работает на высокоразмерных данных. Основной минус — высокое потребление памяти из-за хранения графовой структуры. Построение индекса может быть медленнее, чем у IVF-семейства.

### IVF_PQ (Inverted File Index with Product Quantization)

**Принцип:** Сочетает кластеризацию (IVF) с product quantization — вектор разбивается на `m` подвекторов, каждый из которых квантизуется отдельно в `2^nbits` центроидов. Это значительно сжимает хранимые данные.

**Параметры:**
- `nlist` (128) — количество кластеров (аналогично IVF_FLAT)
- `m` (16) — на сколько подвекторов разбить исходный вектор (dim=384, значит каждый подвектор = 24 компоненты)
- `nbits` (8) — битность квантизации (256 центроидов на подвектор)
- `nprobe` (16) — количество просматриваемых кластеров при поиске

**Trade-off:** Основное преимущество — значительная экономия памяти (каждый вектор занимает `m × nbits / 8` байт вместо `dim × 4` байт). Недостаток — потеря точности из-за квантизации, recall может быть ниже при больших датасетах. На малых датасетах потеря незаметна.

## Результаты бенчмарка

**Условия тестирования:**
- 5 000 документов, эмбеддинги 384 dim
- 100 случайных запросов (seed=42)
- Top-K = 10
- Метрика расстояния: L2
- Baseline: brute-force поиск (numpy)

| Algorithm | Build Time (s) | Avg Latency (ms) | P99 Latency (ms) | Recall@10 |
|-----------|----------------|-------------------|-------------------|-----------|
| IVF_FLAT  | 1.17           | 6.72              | 10.10             | 1.0000    |
| HNSW      | 0.96           | 9.83              | 12.12             | 1.0000    |
| IVF_PQ    | 1.36           | 6.20              | 13.02             | 1.0000    |

## Анализ trade-offs

### Скорость поиска
- **IVF_PQ** показал наименьшую среднюю задержку (6.20 ms) — квантизованные вектора быстрее сравниваются
- **IVF_FLAT** близок по скорости (6.72 ms) — кластерный подход эффективен
- **HNSW** медленнее (9.83 ms) — обход графа имеет бо́льший overhead на малых датасетах

### Скорость построения индекса
- **HNSW** построился быстрее всех (0.96s) — на 5000 документах граф строится быстро
- **IVF_FLAT** — 1.17s (k-means кластеризация)
- **IVF_PQ** — 1.36s (кластеризация + обучение codebook для PQ)

### Точность (Recall@10)
Все три алгоритма показали **Recall@10 = 1.0**. Это объяснимо размером датасета — при 5000 документах и достаточных параметрах поиска (nprobe=16 из 128 кластеров ≈ 12.5% данных, ef=64 для HNSW) все алгоритмы находят точных соседей.

На датасетах масштаба 1M+ записей картина будет другой:
- **IVF_FLAT** будет терять recall при малом nprobe
- **HNSW** сохранит высокий recall благодаря графовой навигации
- **IVF_PQ** покажет наибольшее снижение recall из-за квантизации

### Потребление памяти (теоретическое)
- **IVF_FLAT**: ~7.3 MB (5000 × 384 × 4 bytes) — полные вектора
- **HNSW**: ~7.3 MB + графовая структура (~2× overhead) ≈ 15 MB
- **IVF_PQ**: ~0.08 MB (5000 × 16 bytes) — сжатые вектора, экономия ~90×

## Выводы

| Сценарий | Рекомендуемый алгоритм | Обоснование |
|----------|----------------------|-------------|
| Высокая точность, достаточно памяти | **HNSW** | Лучший recall на больших датасетах, не требует настройки nlist/nprobe |
| Баланс скорости и точности | **IVF_FLAT** | Предсказуемое поведение, тюнинг через nlist/nprobe, точный поиск внутри кластеров |
| Ограниченная память, большой датасет | **IVF_PQ** | Сжатие до 90×, приемлемый recall при правильных параметрах |
| Малый датасет (<100K) | **IVF_FLAT** или **HNSW** | Оба дают recall ≈ 1.0, разница в latency минимальна |
| Максимальная скорость вставки | **IVF_FLAT** | Простая кластеризация без построения графа |